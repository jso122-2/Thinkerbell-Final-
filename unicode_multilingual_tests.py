#!/usr/bin/env python3
"""
üåç Unicode and Multilingual Testing Suite for Thinkerbell Model
=============================================================

This suite tests the model's handling of:
1. Unicode characters and emojis
2. Multiple languages and scripts
3. Right-to-left (RTL) languages
4. Mixed script content
5. Unicode normalization issues
6. Character encoding edge cases
"""

import requests
import json
import unicodedata
import sys
from typing import Dict, List, Any

API_BASE_URL = "http://localhost:8000"

class UnicodeMultilingualTester:
    """Test Unicode and multilingual capabilities"""
    
    def __init__(self, base_url: str = API_BASE_URL):
        self.base_url = base_url
        self.results = []
    
    def test_unicode_case(self, name: str, input_text: str, description: str = "") -> Dict[str, Any]:
        """Test a single Unicode case"""
        print(f"\nüåç Testing: {name}")
        if description:
            print(f"   Description: {description}")
        
        input_data = {
            "human_example": input_text,
            "target_length": 700,
            "style_preference": "professional",
            "document_type": "legal_template"
        }
        
        try:
            response = requests.post(f"{self.base_url}/generate", json=input_data, timeout=30)
            
            result = {
                "test_name": name,
                "input_text": input_text,
                "input_length": len(input_text),
                "input_byte_length": len(input_text.encode('utf-8')),
                "status_code": response.status_code,
                "success": response.status_code == 200,
                "unicode_analysis": self.analyze_unicode(input_text)
            }
            
            if response.status_code == 200:
                data = response.json()
                generated_text = data.get("generated_text", "")
                
                result.update({
                    "generated_text": generated_text,
                    "output_length": len(generated_text),
                    "output_byte_length": len(generated_text.encode('utf-8')),
                    "similarity_score": data.get("similarity_to_example", 0),
                    "word_count": data.get("word_count", 0),
                    "processing_time": data.get("processing_time", 0),
                    "output_unicode_analysis": self.analyze_unicode(generated_text)
                })
                
                # Check if output is reasonable
                if len(generated_text.strip()) < 50:
                    result["warning"] = "Generated text is very short"
                
                print(f"   ‚úÖ Success: {len(generated_text)} chars generated")
                print(f"   Similarity: {data.get('similarity_to_example', 0):.3f}")
                
            else:
                result["error"] = response.text[:200]
                print(f"   ‚ùå Failed: HTTP {response.status_code}")
            
            self.results.append(result)
            return result
            
        except Exception as e:
            result = {
                "test_name": name,
                "input_text": input_text,
                "success": False,
                "error": str(e),
                "unicode_analysis": self.analyze_unicode(input_text)
            }
            self.results.append(result)
            print(f"   ‚ùå Exception: {str(e)}")
            return result
    
    def analyze_unicode(self, text: str) -> Dict[str, Any]:
        """Analyze Unicode properties of text"""
        if not text:
            return {"empty": True}
        
        analysis = {
            "length": len(text),
            "byte_length": len(text.encode('utf-8')),
            "categories": {},
            "scripts": {},
            "has_emojis": False,
            "has_rtl": False,
            "normalization_forms": {}
        }
        
        # Analyze character categories and scripts
        for char in text:
            category = unicodedata.category(char)
            analysis["categories"][category] = analysis["categories"].get(category, 0) + 1
            
            try:
                script = unicodedata.name(char).split()[0] if unicodedata.name(char) else "UNKNOWN"
                analysis["scripts"][script] = analysis["scripts"].get(script, 0) + 1
            except ValueError:
                analysis["scripts"]["UNNAMED"] = analysis["scripts"].get("UNNAMED", 0) + 1
            
            # Check for emojis (simplified check)
            if ord(char) >= 0x1F600 and ord(char) <= 0x1F64F:  # Emoticons
                analysis["has_emojis"] = True
            elif ord(char) >= 0x1F300 and ord(char) <= 0x1F5FF:  # Misc Symbols
                analysis["has_emojis"] = True
            elif ord(char) >= 0x1F680 and ord(char) <= 0x1F6FF:  # Transport
                analysis["has_emojis"] = True
            elif ord(char) >= 0x2600 and ord(char) <= 0x26FF:    # Misc symbols
                analysis["has_emojis"] = True
            
            # Check for RTL characters
            if unicodedata.bidirectional(char) in ['R', 'AL']:
                analysis["has_rtl"] = True
        
        # Check normalization forms
        try:
            analysis["normalization_forms"] = {
                "NFC": unicodedata.normalize('NFC', text) == text,
                "NFD": unicodedata.normalize('NFD', text) == text,
                "NFKC": unicodedata.normalize('NFKC', text) == text,
                "NFKD": unicodedata.normalize('NFKD', text) == text
            }
        except Exception:
            analysis["normalization_forms"] = {"error": "Could not check normalization"}
        
        return analysis
    
    def run_unicode_tests(self) -> List[Dict[str, Any]]:
        """Run comprehensive Unicode tests"""
        print("üåç UNICODE & MULTILINGUAL TEST SUITE")
        print("=" * 50)
        
        # Test 1: Basic Emoji Usage
        self.test_unicode_case(
            "Basic Emojis",
            "I need a contract üìù for social media marketing üì±. The influencer will post content üì∏ and we'll pay them money üí∞. This should be fun! üéâ",
            "Test basic emoji handling"
        )
        
        # Test 2: Emoji Overload
        self.test_unicode_case(
            "Emoji Overload",
            "üéâüöÄüíºüìù‚ú®ü§ùüí∞üì±üì∏üé¨üé≠üåüüíØüî•‚≠êüéØüèÜüíéüé™üé®üéµüéÆüé≤üé≥üéØ Contract for influencer! üéâüöÄüíºüìù‚ú®ü§ùüí∞üì±üì∏üé¨üé≠üåüüíØüî•‚≠êüéØüèÜüíéüé™üé®üéµüéÆüé≤üé≥üéØ",
            "Test excessive emoji usage"
        )
        
        # Test 3: Spanish
        self.test_unicode_case(
            "Spanish Text",
            "Necesito un contrato para marketing de influencers en redes sociales. El influencer publicar√° contenido sobre nuestros productos de belleza en Instagram y TikTok. El pago ser√° de $5000 m√°s productos gratuitos. La colaboraci√≥n durar√° 3 meses con exclusividad en la categor√≠a de belleza.",
            "Test Spanish language processing"
        )
        
        # Test 4: French with Accents
        self.test_unicode_case(
            "French with Accents",
            "J'ai besoin d'un contrat pour le marketing d'influence sur les r√©seaux sociaux. L'influenceur cr√©era du contenu authentique pour notre marque de cosm√©tiques. La r√©mun√©ration comprend un paiement fixe et une commission sur les ventes g√©n√©r√©es.",
            "Test French with accent marks"
        )
        
        # Test 5: German with Umlauts
        self.test_unicode_case(
            "German with Umlauts",
            "Ich ben√∂tige einen Vertrag f√ºr Influencer-Marketing in sozialen Medien. Der Influencer wird √ºber unsere Sch√∂nheitsprodukte posten und daf√ºr bezahlt werden. Die Zusammenarbeit soll professionell und authentisch sein.",
            "Test German umlauts (√§, √∂, √º, √ü)"
        )
        
        # Test 6: Russian Cyrillic
        self.test_unicode_case(
            "Russian Cyrillic",
            "–ú–Ω–µ –Ω—É–∂–µ–Ω –∫–æ–Ω—Ç—Ä–∞–∫—Ç –¥–ª—è –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–∞ –≤ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç—è—Ö. –ò–Ω—Ñ–ª—é–µ–Ω—Å–µ—Ä –±—É–¥–µ—Ç –ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç –æ –Ω–∞—à–∏—Ö –ø—Ä–æ–¥—É–∫—Ç–∞—Ö –∫—Ä–∞—Å–æ—Ç—ã –≤ Instagram –∏ TikTok. –û–ø–ª–∞—Ç–∞ —Å–æ—Å—Ç–∞–≤–∏—Ç $3000 –ø–ª—é—Å –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã.",
            "Test Cyrillic script"
        )
        
        # Test 7: Arabic (RTL)
        self.test_unicode_case(
            "Arabic RTL",
            "ÿ£ÿ≠ÿ™ÿßÿ¨ ÿ•ŸÑŸâ ÿπŸÇÿØ ŸÑŸÑÿ™ÿ≥ŸàŸäŸÇ ÿπÿ®ÿ± Ÿàÿ≥ÿßÿ¶ŸÑ ÿßŸÑÿ™ŸàÿßÿµŸÑ ÿßŸÑÿßÿ¨ÿ™ŸÖÿßÿπŸä. ÿ≥ŸäŸÇŸàŸÖ ÿßŸÑŸÖÿ§ÿ´ÿ± ÿ®ŸÜÿ¥ÿ± ŸÖÿ≠ÿ™ŸàŸâ ÿπŸÜ ŸÖŸÜÿ™ÿ¨ÿßÿ™ ÿßŸÑÿ¨ŸÖÿßŸÑ ÿßŸÑÿÆÿßÿµÿ© ÿ®ŸÜÿß ÿπŸÑŸâ ÿ•ŸÜÿ≥ÿ™ÿ∫ÿ±ÿßŸÖ Ÿàÿ™ŸäŸÉ ÿ™ŸàŸÉ. ÿßŸÑÿØŸÅÿπ ÿ≥ŸäŸÉŸàŸÜ Ÿ•Ÿ†Ÿ†Ÿ† ÿØŸàŸÑÿßÿ± ÿ®ÿßŸÑÿ•ÿ∂ÿßŸÅÿ© ÿ•ŸÑŸâ ŸÖŸÜÿ™ÿ¨ÿßÿ™ ŸÖÿ¨ÿßŸÜŸäÿ©.",
            "Test Arabic right-to-left script"
        )
        
        # Test 8: Hebrew (RTL)
        self.test_unicode_case(
            "Hebrew RTL",
            "◊ê◊†◊ô ◊¶◊®◊ô◊ö ◊ó◊ï◊ñ◊î ◊ú◊©◊ô◊ï◊ï◊ß ◊ë◊®◊©◊™◊ï◊™ ◊î◊ó◊ë◊®◊™◊ô◊ï◊™. ◊î◊û◊©◊§◊ô◊¢◊ü ◊ô◊§◊®◊°◊ù ◊™◊ï◊õ◊ü ◊¢◊ú ◊û◊ï◊¶◊®◊ô ◊î◊ô◊ï◊§◊ô ◊©◊ú◊†◊ï ◊ë◊ê◊ô◊†◊°◊ò◊í◊®◊ù ◊ï◊ë◊ò◊ô◊ß◊ò◊ï◊ß. ◊î◊™◊©◊ú◊ï◊ù ◊ô◊î◊ô◊î ‚Ç™15,000 ◊ë◊™◊ï◊°◊§◊™ ◊û◊ï◊¶◊®◊ô◊ù ◊ó◊ô◊†◊ù.",
            "Test Hebrew right-to-left script"
        )
        
        # Test 9: Japanese (Mixed Scripts)
        self.test_unicode_case(
            "Japanese Mixed Scripts",
            "„Ç§„É≥„Éï„É´„Ç®„É≥„Çµ„Éº„Éû„Éº„Ç±„ÉÜ„Ç£„É≥„Ç∞„ÅÆÂ•ëÁ¥Ñ„ÅåÂøÖË¶Å„Åß„Åô„ÄÇ„Ç§„É≥„Éï„É´„Ç®„É≥„Çµ„Éº„ÅØÁßÅ„Åü„Å°„ÅÆÁæéÂÆπË£ΩÂìÅ„Å´„Å§„ÅÑ„Å¶Instagram„Å®TikTok„Å´ÊäïÁ®ø„Åó„Åæ„Åô„ÄÇÂ†±ÈÖ¨„ÅØ$5000„Å®ÁÑ°ÊñôË£ΩÂìÅ„Åß„Åô„ÄÇ3„É∂ÊúàÈñì„ÅÆÁã¨Âç†Â•ëÁ¥Ñ„Åß„Åô„ÄÇ",
            "Test Japanese with Hiragana, Katakana, and Kanji"
        )
        
        # Test 10: Chinese Simplified
        self.test_unicode_case(
            "Chinese Simplified",
            "ÊàëÈúÄË¶Å‰∏Ä‰ªΩÁ§æ‰∫§Â™í‰ΩìÂΩ±ÂìçËÄÖËê•ÈîÄÂêàÂêå„ÄÇÂΩ±ÂìçËÄÖÂ∞ÜÂú®InstagramÂíåTikTok‰∏äÂèëÂ∏ÉÂÖ≥‰∫éÊàë‰ª¨ÁæéÂÆπ‰∫ßÂìÅÁöÑÂÜÖÂÆπ„ÄÇÊä•ÈÖ¨ÊòØ5000ÁæéÂÖÉÂä†ÂÖçË¥π‰∫ßÂìÅ„ÄÇÂêà‰ΩúÊúü‰∏∫3‰∏™ÊúàÔºåÂú®ÁæéÂÆπÁ±ªÂà´‰∏≠ÂÖ∑ÊúâÁã¨ÂÆ∂ÊÄß„ÄÇ",
            "Test Simplified Chinese characters"
        )
        
        # Test 11: Chinese Traditional
        self.test_unicode_case(
            "Chinese Traditional",
            "ÊàëÈúÄË¶Å‰∏Ä‰ªΩÁ§æ‰∫§Â™íÈ´îÂΩ±ÈüøËÄÖÁáüÈä∑ÂêàÂêå„ÄÇÂΩ±ÈüøËÄÖÂ∞áÂú®InstagramÂíåTikTok‰∏äÁôºÂ∏ÉÈóúÊñºÊàëÂÄëÁæéÂÆπÁî¢ÂìÅÁöÑÂÖßÂÆπ„ÄÇÂ†±ÈÖ¨ÊòØ5000ÁæéÂÖÉÂä†ÂÖçË≤ªÁî¢ÂìÅ„ÄÇÂêà‰ΩúÊúüÁÇ∫3ÂÄãÊúàÔºåÂú®ÁæéÂÆπÈ°ûÂà•‰∏≠ÂÖ∑ÊúâÁç®ÂÆ∂ÊÄß„ÄÇ",
            "Test Traditional Chinese characters"
        )
        
        # Test 12: Korean
        self.test_unicode_case(
            "Korean Hangul",
            "ÏÜåÏÖú ÎØ∏ÎîîÏñ¥ Ïù∏ÌîåÎ£®Ïñ∏ÏÑú ÎßàÏºÄÌåÖ Í≥ÑÏïΩÏù¥ ÌïÑÏöîÌï©ÎãàÎã§. Ïù∏ÌîåÎ£®Ïñ∏ÏÑúÎäî InstagramÍ≥º TikTokÏóêÏÑú Ïö∞Î¶¨ Î∑∞Ìã∞ Ï†úÌíàÏóê ÎåÄÌïú ÏΩòÌÖêÏ∏†Î•º Í≤åÏãúÌï† Í≤ÉÏûÖÎãàÎã§. Î≥¥ÏÉÅÏùÄ $5000ÏôÄ Î¨¥Î£å Ï†úÌíàÏûÖÎãàÎã§.",
            "Test Korean Hangul script"
        )
        
        # Test 13: Thai
        self.test_unicode_case(
            "Thai Script",
            "‡∏â‡∏±‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î‡∏ú‡πà‡∏≤‡∏ô‡∏≠‡∏¥‡∏ô‡∏ü‡∏•‡∏π‡πÄ‡∏≠‡∏ô‡πÄ‡∏ã‡∏≠‡∏£‡πå‡πÉ‡∏ô‡πÇ‡∏ã‡πÄ‡∏ä‡∏µ‡∏¢‡∏•‡∏°‡∏µ‡πÄ‡∏î‡∏µ‡∏¢ ‡∏≠‡∏¥‡∏ô‡∏ü‡∏•‡∏π‡πÄ‡∏≠‡∏ô‡πÄ‡∏ã‡∏≠‡∏£‡πå‡∏à‡∏∞‡πÇ‡∏û‡∏™‡∏ï‡πå‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏á‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡πÉ‡∏ô Instagram ‡πÅ‡∏•‡∏∞ TikTok",
            "Test Thai script with complex characters"
        )
        
        # Test 14: Hindi Devanagari
        self.test_unicode_case(
            "Hindi Devanagari",
            "‡§Æ‡•Å‡§ù‡•á ‡§∏‡•ã‡§∂‡§≤ ‡§Æ‡•Ä‡§°‡§ø‡§Ø‡§æ ‡§á‡§®‡•ç‡§´‡•ç‡§≤‡•Å‡§è‡§Ç‡§∏‡§∞ ‡§Æ‡§æ‡§∞‡•ç‡§ï‡•á‡§ü‡§ø‡§Ç‡§ó ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§Ö‡§®‡•Å‡§¨‡§Ç‡§ß ‡§ö‡§æ‡§π‡§ø‡§è‡•§ ‡§á‡§®‡•ç‡§´‡•ç‡§≤‡•Å‡§è‡§Ç‡§∏‡§∞ Instagram ‡§î‡§∞ TikTok ‡§™‡§∞ ‡§π‡§Æ‡§æ‡§∞‡•á ‡§¨‡•ç‡§Ø‡•Ç‡§ü‡•Ä ‡§™‡•ç‡§∞‡•ã‡§°‡§ï‡•ç‡§ü‡•ç‡§∏ ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§ï‡§Ç‡§ü‡•á‡§Ç‡§ü ‡§™‡•ã‡§∏‡•ç‡§ü ‡§ï‡§∞‡•á‡§ó‡§æ‡•§",
            "Test Hindi Devanagari script"
        )
        
        # Test 15: Mixed Languages
        self.test_unicode_case(
            "Mixed Languages",
            "I need a contrato for marketing en espa√±ol, fran√ßais, and ‰∏≠Êñá. The influencer will post contenido on Instagram y TikTok about notre produits de beaut√© ÁæéÂÆπ‰∫ßÂìÅ.",
            "Test mixed language input"
        )
        
        # Test 16: Unicode Control Characters
        self.test_unicode_case(
            "Unicode Control Characters",
            f"Contract\u0000with\u0001control\u0002characters\u0003and\u0004zero\u0005width\u200B\u200C\u200D\uFEFFspaces",
            "Test Unicode control and zero-width characters"
        )
        
        # Test 17: Combining Characters
        self.test_unicode_case(
            "Combining Characters",
            "Contract with combining characters: √© (e + ÃÅ), √± (n + ÃÉ), √º (u + Ãà), √• (a + Ãä)",
            "Test combining diacritical marks"
        )
        
        # Test 18: Surrogate Pairs
        self.test_unicode_case(
            "Surrogate Pairs",
            "Contract with surrogate pairs: ùïãùïôùïöùï§ ùïöùï§ ùïûùïíùï•ùïôùïñùïûùïíùï•ùïöùïîùïíùïù ùïïùï†ùï¶ùïìùïùùïñ-ùï§ùï•ùï£ùï¶ùïîùïú ùïîùïôùïíùï£ùïíùïîùï•ùïñùï£ùï§ üé≠üé™üé®",
            "Test Unicode surrogate pairs (high/low surrogates)"
        )
        
        # Test 19: Normalization Issues
        text_nfc = "caf√©"  # NFC normalized
        text_nfd = "cafe\u0301"  # NFD normalized (e + combining acute)
        self.test_unicode_case(
            "Normalization NFC vs NFD",
            f"Contract for {text_nfc} and {text_nfd} - these should look the same but have different Unicode representations",
            "Test Unicode normalization differences"
        )
        
        # Test 20: Bidirectional Text (Mixed LTR/RTL)
        self.test_unicode_case(
            "Bidirectional Text",
            "Contract between Company Inc. and ÿ¥ÿ±ŸÉÿ© ÿßŸÑÿ™ÿ≥ŸàŸäŸÇ ÿßŸÑÿ±ŸÇŸÖŸä for marketing campaign on Instagram Ÿà TikTok with payment of $5000 Ÿà ŸÖŸÜÿ™ÿ¨ÿßÿ™ ŸÖÿ¨ÿßŸÜŸäÿ©",
            "Test mixed left-to-right and right-to-left text"
        )
        
        return self.results
    
    def generate_summary(self) -> Dict[str, Any]:
        """Generate test summary"""
        if not self.results:
            return {"error": "No test results available"}
        
        total_tests = len(self.results)
        successful_tests = sum(1 for r in self.results if r.get("success", False))
        failed_tests = total_tests - successful_tests
        
        # Analyze Unicode categories tested
        categories_tested = set()
        scripts_tested = set()
        
        for result in self.results:
            if "unicode_analysis" in result:
                analysis = result["unicode_analysis"]
                if "categories" in analysis:
                    categories_tested.update(analysis["categories"].keys())
                if "scripts" in analysis:
                    scripts_tested.update(analysis["scripts"].keys())
        
        summary = {
            "total_tests": total_tests,
            "successful_tests": successful_tests,
            "failed_tests": failed_tests,
            "success_rate": (successful_tests / total_tests * 100) if total_tests > 0 else 0,
            "unicode_categories_tested": len(categories_tested),
            "scripts_tested": len(scripts_tested),
            "categories": sorted(list(categories_tested)),
            "scripts": sorted(list(scripts_tested))
        }
        
        return summary

def main():
    """Main test runner"""
    # Check server connection
    try:
        response = requests.get(f"{API_BASE_URL}/health", timeout=5)
        if response.status_code != 200:
            print(f"‚ùå Server not ready: {response.status_code}")
            sys.exit(1)
        print("‚úÖ Server connection verified")
    except requests.exceptions.ConnectionError:
        print(f"‚ùå Cannot connect to server at {API_BASE_URL}")
        print("Make sure the backend server is running: python backend_api_server.py")
        sys.exit(1)
    
    # Run tests
    tester = UnicodeMultilingualTester()
    results = tester.run_unicode_tests()
    
    # Generate and display summary
    summary = tester.generate_summary()
    
    print("\n" + "=" * 50)
    print("üìä UNICODE & MULTILINGUAL TEST SUMMARY")
    print("=" * 50)
    print(f"Total Tests: {summary['total_tests']}")
    print(f"Successful: {summary['successful_tests']} ‚úÖ")
    print(f"Failed: {summary['failed_tests']} ‚ùå")
    print(f"Success Rate: {summary['success_rate']:.1f}%")
    print(f"Unicode Categories Tested: {summary['unicode_categories_tested']}")
    print(f"Scripts Tested: {summary['scripts_tested']}")
    
    if summary['failed_tests'] > 0:
        print("\n‚ùå FAILED TESTS:")
        for result in results:
            if not result.get("success", False):
                print(f"  - {result['test_name']}")
                if "error" in result:
                    print(f"    Error: {result['error']}")
    
    # Save detailed results
    import time
    timestamp = int(time.time())
    filename = f"unicode_test_results_{timestamp}.json"
    
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump({
            "summary": summary,
            "detailed_results": results
        }, f, indent=2, ensure_ascii=False)
    
    print(f"\nüíæ Detailed results saved to: {filename}")

if __name__ == "__main__":
    main()
